{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d26f594b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 예측 확률: 0.9551734777411631\n",
      "상위 10개 확률: [np.float64(0.9551734777411631), np.float64(0.9495232975734985), np.float64(0.948161903186157), np.float64(0.9479109969845085), np.float64(0.9477034068176335), np.float64(0.9448529931520346), np.float64(0.9445799202411178), np.float64(0.9430131530163884), np.float64(0.9428614048341629), np.float64(0.9425255400061279)]\n",
      "최대 예측 확률: 0.9551734777411631\n",
      "상위 10개 확률: [np.float64(0.9551734777411631), np.float64(0.9495232975734985), np.float64(0.948161903186157), np.float64(0.9479109969845085), np.float64(0.9448529931520346), np.float64(0.9445799202411178), np.float64(0.9430131530163884), np.float64(0.9428614048341629), np.float64(0.9425255400061279), np.float64(0.9422511236838137)]\n",
      "\n",
      "최대 확률 row의 feature 값:\n",
      "amenities_cnt                              22\n",
      "availability_365                          206\n",
      "price                                    53.0\n",
      "host_about_length_group                 empty\n",
      "room_type                     Entire home/apt\n",
      "name_length_group                        long\n",
      "description_length_group         short_or_avg\n",
      "host_has_profile_pic                        1\n",
      "host_response_time_score                  4.0\n",
      "type_amenity_score                      0.333\n",
      "common_amenity_score                      1.0\n",
      "host_acceptance_rate_score                  4\n",
      "host_identity_verified                      1\n",
      "is_long_term                                1\n",
      "accommodates                                1\n",
      "Name: 1123776431230095841, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "csv_path = 'superhost.csv'    # 여기에 absolute path\n",
    "# CSV 읽기\n",
    "df = pd.read_csv(\n",
    "    csv_path,\n",
    "    header=0,        # 첫 줄을 컬럼명으로 사용\n",
    "    index_col='id',  # 인덱스 컬럼으로 id 지정\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "\n",
    "# 1. 타겟 및 피처 정의\n",
    "TARGET = 'host_is_superhost'\n",
    "\n",
    "strategy_cols = ['amenities_cnt', 'availability_365', 'price', 'host_about_length_group', 'room_type','name_length_group', 'description_length_group',\n",
    "                 'host_has_profile_pic', 'host_response_time_score','type_amenity_score','common_amenity_score',\n",
    "                 'host_acceptance_rate_score', 'host_identity_verified','is_long_term', 'accommodates']\n",
    "\n",
    "X = df[strategy_cols]\n",
    "y = df[TARGET].astype(int)\n",
    "\n",
    "# 2. 열 타입 분리\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# 3. 전처리 파이프라인 구성\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop=None), categorical_cols)\n",
    "], remainder='passthrough')  # 수치형은 그대로 통과\n",
    "\n",
    "# 4. 전체 파이프라인 구성\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(\n",
    "        n_estimators=1000,\n",
    "        max_depth=30,\n",
    "        min_samples_split=15,\n",
    "        min_samples_leaf=10,\n",
    "        random_state=42,\n",
    "        class_weight='balanced'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 5. 학습 데이터 분할 및 모델 학습\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "proba = pipeline.predict_proba(X)[:, 1]\n",
    "print(\"최대 예측 확률:\", proba.max())\n",
    "print(\"상위 10개 확률:\", sorted(proba, reverse=True)[:10])\n",
    "\n",
    "proba = pipeline.predict_proba(X_train)[:, 1]\n",
    "idx = proba.argmax()\n",
    "print(\"최대 예측 확률:\", proba[idx])\n",
    "print(\"상위 10개 확률:\", sorted(proba, reverse=True)[:10])\n",
    "print(\"\\n최대 확률 row의 feature 값:\")\n",
    "print(X_train.iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687d5d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일을 성공적으로 로드했습니다.\n",
      "범주형 컬럼: ['host_about_length_group', 'room_type', 'name_length_group', 'description_length_group', 'host_has_profile_pic', 'host_identity_verified', 'is_long_term']\n",
      "수치형 컬럼: ['amenities_cnt', 'availability_365', 'price', 'host_response_time_score', 'type_amenity_score', 'common_amenity_score', 'host_acceptance_rate_score', 'accommodates']\n",
      "\n",
      "학습 데이터 크기 (X_train): (17846, 15)\n",
      "테스트 데이터 크기 (X_test): (4462, 15)\n",
      "학습 데이터의 슈퍼호스트 비율: host_is_superhost\n",
      "0    0.72498\n",
      "1    0.27502\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "하이퍼파라미터 튜닝을 시작합니다. (시간이 오래 걸릴 수 있습니다...)\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HY\\AppData\\Local\\Temp\\ipykernel_18292\\3076542489.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].astype(object) # object 타입으로 변환하여 categorical_cols에 포함되도록 함\n",
      "C:\\Users\\HY\\AppData\\Local\\Temp\\ipykernel_18292\\3076542489.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].astype(object) # object 타입으로 변환하여 categorical_cols에 포함되도록 함\n",
      "C:\\Users\\HY\\AppData\\Local\\Temp\\ipykernel_18292\\3076542489.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].astype(object) # object 타입으로 변환하여 categorical_cols에 포함되도록 함\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV # GridSearchCV 추가\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score # 모델 평가 지표 확인용\n",
    "\n",
    "# --- 0. 데이터 로드 ---\n",
    "# 'superhost.csv' 파일의 절대 경로를 지정해주세요.\n",
    "# 예: csv_path = 'C:/Users/HY/Documents/GitHub/advanced_project/hayoung/data/superhost.csv'\n",
    "csv_path = 'superhost.csv'  # 현재 스크립트와 같은 디렉토리에 있다면 상대 경로도 가능\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        csv_path,\n",
    "        header=0,\n",
    "        index_col='id',\n",
    "        encoding='utf-8-sig'\n",
    "    )\n",
    "    print(\"CSV 파일을 성공적으로 로드했습니다.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: '{csv_path}' 파일을 찾을 수 없습니다. 경로를 확인해주세요.\")\n",
    "    exit() # 파일이 없으면 스크립트 종료\n",
    "\n",
    "# 1. 타겟 및 피처 정의\n",
    "TARGET = 'host_is_superhost'\n",
    "\n",
    "strategy_cols = [\n",
    "    'amenities_cnt', 'availability_365', 'price',\n",
    "    'host_about_length_group', 'room_type', 'name_length_group', 'description_length_group',\n",
    "    'host_has_profile_pic', 'host_response_time_score', 'type_amenity_score', 'common_amenity_score',\n",
    "    'host_acceptance_rate_score', 'host_identity_verified', 'is_long_term', 'accommodates'\n",
    "]\n",
    "\n",
    "# 결측치 확인 및 제거 (필요하다면)\n",
    "# df.dropna(subset=strategy_cols + [TARGET], inplace=True)\n",
    "# print(f\"결측치 처리 후 데이터 크기: {df.shape}\")\n",
    "\n",
    "X = df[strategy_cols]\n",
    "y = df[TARGET].astype(int) # 타겟 변수는 정수형으로\n",
    "\n",
    "# 2. 열 타입 분리\n",
    "# OneHotEncoder는 bool 타입을 자동으로 처리하지 못할 수 있으므로, object/category로 명시적으로 변환\n",
    "for col in ['host_has_profile_pic', 'host_identity_verified', 'is_long_term']:\n",
    "    if col in X.columns:\n",
    "        X[col] = X[col].astype(object) # object 타입으로 변환하여 categorical_cols에 포함되도록 함\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"범주형 컬럼: {categorical_cols}\")\n",
    "print(f\"수치형 컬럼: {numerical_cols}\")\n",
    "\n",
    "# 3. 전처리 파이프라인 구성\n",
    "# DropNone은 OneHotEncoder가 모든 범주를 유지\n",
    "# handle_unknown='ignore'는 훈련 데이터에 없는 범주가 예측 단계에서 나타날 경우 무시\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop=None), categorical_cols)\n",
    "], remainder='passthrough') # 수치형은 그대로 통과\n",
    "\n",
    "# 4. 전체 파이프라인 구성\n",
    "# 초기 RandomForestClassifier는 튜닝을 위한 기본 설정\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced')) # class_weight='balanced' 유지\n",
    "])\n",
    "\n",
    "# 5. 학습 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n학습 데이터 크기 (X_train): {X_train.shape}\")\n",
    "print(f\"테스트 데이터 크기 (X_test): {X_test.shape}\")\n",
    "print(f\"학습 데이터의 슈퍼호스트 비율: {y_train.value_counts(normalize=True)}\")\n",
    "\n",
    "# --- 6. 하이퍼파라미터 그리드 정의 ---\n",
    "# 'classifier__' 접두사를 사용하여 Pipeline 내의 classifier 단계의 파라미터를 지정\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [500, 1000, 1500], # 트리의 개수 (추가 탐색: 500, 1000, 1500)\n",
    "    'classifier__max_depth': [20, 30, 40, None], # 트리의 최대 깊이 (None은 제한 없음)\n",
    "    'classifier__min_samples_split': [2, 5, 10, 15], # 노드를 분할하기 위한 최소 샘플 수\n",
    "    'classifier__min_samples_leaf': [1, 2, 5, 10],   # 리프 노드가 가져야 할 최소 샘플 수\n",
    "    # 'classifier__class_weight': ['balanced', None] # 불균형이 심하다면 balanced 유지. 아니면 탐색.\n",
    "                                                   # 여기서는 이미 'balanced'로 고정\n",
    "}\n",
    "\n",
    "# --- 7. GridSearchCV를 이용한 하이퍼파라미터 튜닝 ---\n",
    "print(\"\\n하이퍼파라미터 튜닝을 시작합니다. (시간이 오래 걸릴 수 있습니다...)\")\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5, # 5-폴드 교차 검증\n",
    "    scoring='f1', # 슈퍼호스트 예측이 중요하므로 f1-score를 최적화 지표로 선택\n",
    "                  # 'accuracy', 'roc_auc' 등 다른 지표도 가능\n",
    "    n_jobs=-1,    # 가능한 모든 CPU 코어 사용\n",
    "    verbose=2     # 자세한 진행 상황 출력\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n--- 하이퍼파라미터 튜닝 완료 ---\")\n",
    "print(f\"최적의 하이퍼파라미터: {grid_search.best_params_}\")\n",
    "print(f\"최적의 F1-Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# 최적의 모델 (파이프라인) 가져오기\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "# --- 8. 최적 모델 평가 ---\n",
    "print(\"\\n--- 최적 모델 성능 평가 (테스트 세트) ---\")\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "y_pred_proba = best_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "\n",
    "# --- 9. 최적 파이프라인 저장 ---\n",
    "model_save_path = 'superhost_pipeline_rf_tuned.pkl' # 튜닝된 모델임을 명시\n",
    "joblib.dump(best_pipeline, model_save_path)\n",
    "print(f\"\\n최적화된 파이프라인 모델을 '{model_save_path}'로 저장했습니다.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "880cddf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일을 성공적으로 로드했습니다.\n",
      "범주형 컬럼: ['host_about_length_group', 'room_type', 'name_length_group', 'description_length_group', 'host_has_profile_pic', 'host_identity_verified', 'is_long_term']\n",
      "수치형 컬럼: ['amenities_cnt', 'availability_365', 'price', 'host_response_time_score', 'type_amenity_score', 'common_amenity_score', 'host_acceptance_rate_score', 'accommodates']\n",
      "\n",
      "학습 데이터 크기 (X_train): (17846, 15)\n",
      "테스트 데이터 크기 (X_test): (4462, 15)\n",
      "학습 데이터의 슈퍼호스트 비율: host_is_superhost\n",
      "0    0.72498\n",
      "1    0.27502\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "하이퍼파라미터 튜닝을 시작합니다. (RandomizedSearchCV 사용 - 훨씬 빠름)\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HY\\AppData\\Local\\Temp\\ipykernel_21284\\457813262.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].astype(object)\n",
      "C:\\Users\\HY\\AppData\\Local\\Temp\\ipykernel_21284\\457813262.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].astype(object)\n",
      "C:\\Users\\HY\\AppData\\Local\\Temp\\ipykernel_21284\\457813262.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].astype(object)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 하이퍼파라미터 튜닝 완료 ---\n",
      "최적의 하이퍼파라미터: {'classifier__n_estimators': 1500, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 2, 'classifier__max_depth': 20}\n",
      "최적의 F1-Score: 0.6455\n",
      "\n",
      "--- 최적 모델 성능 평가 (테스트 세트) ---\n",
      "Accuracy: 0.8005\n",
      "Precision: 0.6262\n",
      "Recall: 0.6813\n",
      "F1-Score: 0.6526\n",
      "ROC-AUC: 0.8657\n",
      "\n",
      "최적화된 파이프라인 모델을 'superhost_pipeline_rf_tuned.pkl'로 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# GridSearchCV 대신 RandomizedSearchCV 임포트\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# --- 0. 데이터 로드 ---\n",
    "csv_path = 'superhost.csv'\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        csv_path,\n",
    "        header=0,\n",
    "        index_col='id',\n",
    "        encoding='utf-8-sig'\n",
    "    )\n",
    "    print(\"CSV 파일을 성공적으로 로드했습니다.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: '{csv_path}' 파일을 찾을 수 없습니다. 경로를 확인해주세요.\")\n",
    "    exit()\n",
    "\n",
    "# 1. 타겟 및 피처 정의\n",
    "TARGET = 'host_is_superhost'\n",
    "\n",
    "strategy_cols = [\n",
    "    'amenities_cnt', 'availability_365', 'price',\n",
    "    'host_about_length_group', 'room_type', 'name_length_group', 'description_length_group',\n",
    "    'host_has_profile_pic', 'host_response_time_score', 'type_amenity_score', 'common_amenity_score',\n",
    "    'host_acceptance_rate_score', 'host_identity_verified', 'is_long_term', 'accommodates'\n",
    "]\n",
    "\n",
    "X = df[strategy_cols]\n",
    "y = df[TARGET].astype(int)\n",
    "\n",
    "# 2. 열 타입 분리 (OneHotEncoder가 bool 타입을 object로 인식하도록 명시적 변환)\n",
    "for col in ['host_has_profile_pic', 'host_identity_verified', 'is_long_term']:\n",
    "    if col in X.columns:\n",
    "        X[col] = X[col].astype(object)\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"범주형 컬럼: {categorical_cols}\")\n",
    "print(f\"수치형 컬럼: {numerical_cols}\")\n",
    "\n",
    "# 3. 전처리 파이프라인 구성\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop=None), categorical_cols)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# 4. 전체 파이프라인 구성\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# 5. 학습 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n학습 데이터 크기 (X_train): {X_train.shape}\")\n",
    "print(f\"테스트 데이터 크기 (X_test): {X_test.shape}\")\n",
    "print(f\"학습 데이터의 슈퍼호스트 비율: {y_train.value_counts(normalize=True)}\")\n",
    "\n",
    "# --- 6. 하이퍼파라미터 그리드 정의 ---\n",
    "# RandomizedSearchCV는 param_distributions 파라미터를 사용\n",
    "param_dist = {\n",
    "    'classifier__n_estimators': [500, 1000, 1500],\n",
    "    'classifier__max_depth': [20, 30, 40, None],\n",
    "    'classifier__min_samples_split': [2, 5, 10, 15],\n",
    "    'classifier__min_samples_leaf': [1, 2, 5, 10],\n",
    "}\n",
    "\n",
    "# --- 7. RandomizedSearchCV를 이용한 하이퍼파라미터 튜닝 ---\n",
    "print(\"\\n하이퍼파라미터 튜닝을 시작합니다. (RandomizedSearchCV 사용 - 훨씬 빠름)\")\n",
    "random_search = RandomizedSearchCV( # <-- 여기를 RandomizedSearchCV로 변경\n",
    "    pipeline,\n",
    "    param_distributions=param_dist, # <-- 여기를 param_distributions로 변경\n",
    "    n_iter=50,  \n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=2,  \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 학습 시작\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n--- 하이퍼파라미터 튜닝 완료 ---\")\n",
    "print(f\"최적의 하이퍼파라미터: {random_search.best_params_}\")\n",
    "print(f\"최적의 F1-Score: {random_search.best_score_:.4f}\")\n",
    "\n",
    "# 최적의 모델 (파이프라인) 가져오기\n",
    "best_pipeline = random_search.best_estimator_ # <-- random_search.best_estimator_ 사용\n",
    "\n",
    "# --- 8. 최적 모델 평가 ---\n",
    "print(\"\\n--- 최적 모델 성능 평가 (테스트 세트) ---\")\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "y_pred_proba = best_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "\n",
    "# --- 9. 최적 파이프라인 저장 ---\n",
    "model_save_path = 'superhost_pipeline_rf_tuned.pkl'\n",
    "joblib.dump(best_pipeline, model_save_path)\n",
    "print(f\"\\n최적화된 파이프라인 모델을 '{model_save_path}'로 저장했습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
